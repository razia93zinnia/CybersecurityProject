{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d08528",
   "metadata": {},
   "source": [
    "# Virus Data Collector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3370b",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fab7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70719599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURATION =====\n",
    "API_KEY = '2117ff9ed05bbfde342deec3c7e417fa98cd4068adb477f43ac3c1d58e29431a'  # Your API key\n",
    "DELAY_BETWEEN_REQUESTS = 16  # seconds (free tier: 4 req/min)\n",
    "\n",
    "headers = {\"x-apikey\": API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c04a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== HELPER FUNCTIONS =====\n",
    "\n",
    "# Read hash values from a CSV file\n",
    "def read_hash_file(file_name: str, hash_col: str = \"hash\") -> List[Dict]:\n",
    "    # List to store hash info\n",
    "    hash_data = []\n",
    "    try:\n",
    "        with open(file_name, newline='', encoding='utf-8') as fh:\n",
    "            reader = csv.DictReader(fh)  # Open CSV as dictionary reader\n",
    "            \n",
    "            # Check if headers exist\n",
    "            if reader.fieldnames is None:\n",
    "                raise ValueError(\"CSV file appears to have no header row.\")\n",
    "            \n",
    "            # Ensure hash column exists\n",
    "            if hash_col not in reader.fieldnames:\n",
    "                raise ValueError(f\"Column '{hash_col}' not found in CSV header: {reader.fieldnames}\")\n",
    "\n",
    "            # Iterate each row and extract hash and related info\n",
    "            for row in reader:\n",
    "                raw_hash = row.get(hash_col, \"\").strip().lower()\n",
    "                # Skip empty or example hashes\n",
    "                if raw_hash and raw_hash != \"example_hash_here\":\n",
    "                    hash_data.append({\n",
    "                        'hash': raw_hash,\n",
    "                        'family': row.get('malware_family', 'Unknown'),\n",
    "                        'source': row.get('source', 'Unknown')\n",
    "                    })\n",
    "        \n",
    "        # Print number of hashes loaded\n",
    "        print(f\"âœ“ Loaded {len(hash_data)} hashes from {file_name}\")\n",
    "        return hash_data\n",
    "    \n",
    "    # Handle file not found error\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âœ— Error: File '{file_name}' not found!\")\n",
    "        return []\n",
    "    # Handle other exceptions\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error reading file: {e}\")\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff610d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the file report from VirusTotal API given a hash\n",
    "def get_file_report(hash_val: str) -> Dict:\n",
    "    url = f\"https://www.virustotal.com/api/v3/files/{hash_val}\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        # Successful response\n",
    "        if response.status_code == 200:\n",
    "            return {'success': True, 'data': response.json()}\n",
    "        # Hash not found on VirusTotal\n",
    "        elif response.status_code == 404:\n",
    "            return {'success': False, 'error': 'Hash not found on VirusTotal'}\n",
    "        # Other errors\n",
    "        else:\n",
    "            return {'success': False, 'error': f'Error {response.status_code}'}\n",
    "    except Exception as e:\n",
    "        return {'success': False, 'error': str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df99c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get behavior/sandbox report from VirusTotal API for a given hash\n",
    "def get_behavior_report(hash_val: str) -> Dict:\n",
    "    url = f\"https://www.virustotal.com/api/v3/files/{hash_val}/behaviour_summary\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        # Successful response\n",
    "        if response.status_code == 200:\n",
    "            return {'success': True, 'data': response.json()}\n",
    "        # No behavior data available for hash\n",
    "        elif response.status_code == 404:\n",
    "            return {'success': False, 'error': 'No behavior data available'}\n",
    "        # Other errors\n",
    "        else:\n",
    "            return {'success': False, 'error': f'Error {response.status_code}'}\n",
    "    except Exception as e:\n",
    "        return {'success': False, 'error': str(e)}\n",
    "\n",
    "# Extract key behavioral indicators from the sandbox report JSON\n",
    "def extract_behavioral_indicators(behavior_data: Dict) -> Dict:\n",
    "    # Prepare empty lists to collect indicators\n",
    "    indicators = {\n",
    "        'processes_created': [],\n",
    "        'files_written': [],\n",
    "        'files_deleted': [],\n",
    "        'registry_keys_set': [],\n",
    "        'registry_keys_deleted': [],\n",
    "        'dns_lookups': [],\n",
    "        'ip_traffic': [],\n",
    "        'http_conversations': [],\n",
    "        'command_executions': [],\n",
    "        'mutexes_created': [],\n",
    "        'services_created': [],\n",
    "        'mitre_techniques': []\n",
    "    }\n",
    "    \n",
    "    # If behavior data unsuccessful, return empty indicators\n",
    "    if not behavior_data.get('success'):\n",
    "        return indicators\n",
    "    \n",
    "    # Extract attributes from response JSON\n",
    "    data = behavior_data.get('data', {}).get('data', {}).get('attributes', {})\n",
    "    \n",
    "    # Extract various indicators if they exist in data\n",
    "    if 'processes_created' in data:\n",
    "        indicators['processes_created'] = data['processes_created']\n",
    "    if 'files_written' in data:\n",
    "        indicators['files_written'] = data['files_written']\n",
    "    if 'files_deleted' in data:\n",
    "        indicators['files_deleted'] = data['files_deleted']\n",
    "    if 'registry_keys_set' in data:\n",
    "        indicators['registry_keys_set'] = data['registry_keys_set']\n",
    "    if 'registry_keys_deleted' in data:\n",
    "        indicators['registry_keys_deleted'] = data['registry_keys_deleted']\n",
    "    if 'dns_lookups' in data:\n",
    "        indicators['dns_lookups'] = [lookup.get('hostname', '') for lookup in data['dns_lookups']]\n",
    "    if 'ip_traffic' in data:\n",
    "        indicators['ip_traffic'] = [f\"{ip.get('destination_ip', '')}:{ip.get('destination_port', '')}\" \n",
    "                                     for ip in data['ip_traffic']]\n",
    "    if 'http_conversations' in data:\n",
    "        indicators['http_conversations'] = [conv.get('url', '') for conv in data['http_conversations']]\n",
    "    if 'command_executions' in data:\n",
    "        indicators['command_executions'] = data['command_executions']\n",
    "    if 'mutexes_created' in data:\n",
    "        indicators['mutexes_created'] = data['mutexes_created']\n",
    "    if 'mitre_attack_techniques' in data:\n",
    "        indicators['mitre_techniques'] = data['mitre_attack_techniques']\n",
    "    \n",
    "    return indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43526667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VirusTotal Malware Data Collection Script\n",
      "============================================================\n",
      "\n",
      "âœ— Error: File './output/hash_signature_output.csv' not found!\n",
      "No hashes found. Please check your input file.\n",
      "Found 0 hashes to process\n",
      "\n",
      "Preview of samples:\n"
     ]
    }
   ],
   "source": [
    "# Collect data for all malware hash samples and save results to files\n",
    "def collect_sample_data(hash_data_list: List[Dict], output_dir: str = \"output\"):\n",
    "    # Create output directories if they do not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(f\"{output_dir}/raw_responses\", exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    total = len(hash_data_list)\n",
    "    \n",
    "    # Print start info and estimated total time\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting data collection for {total} samples...\")\n",
    "    print(f\"Estimated time: {(total * DELAY_BETWEEN_REQUESTS) / 60:.1f} minutes\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Loop through hashes one by one\n",
    "    for idx, hash_info in enumerate(hash_data_list, 1):\n",
    "        hash_val = hash_info['hash']\n",
    "        family = hash_info['family']\n",
    "        \n",
    "        print(f\"[{idx}/{total}] Processing: {hash_val[:16]}... ({family})\")\n",
    "        \n",
    "        # Get file report from VirusTotal\n",
    "        print(f\"  â†’ Fetching file report...\")\n",
    "        file_report = get_file_report(hash_val)\n",
    "        \n",
    "        # If file report failed, record failure and continue to next item\n",
    "        if not file_report['success']:\n",
    "            print(f\"  âœ— {file_report['error']}\")\n",
    "            results.append({\n",
    "                'hash': hash_val,\n",
    "                'family': family,\n",
    "                'status': 'failed',\n",
    "                'error': file_report['error']\n",
    "            })\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "            continue\n",
    "        \n",
    "        # Wait to respect rate limit\n",
    "        time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "        \n",
    "        # Get behavioral report from VirusTotal\n",
    "        print(f\"  â†’ Fetching behavior report...\")\n",
    "        behavior_report = get_behavior_report(hash_val)\n",
    "        \n",
    "        # Save raw JSON responses to files\n",
    "        with open(f\"{output_dir}/raw_responses/{hash_val}_file.json\", 'w') as f:\n",
    "            json.dump(file_report, f, indent=2)\n",
    "        with open(f\"{output_dir}/raw_responses/{hash_val}_behavior.json\", 'w') as f:\n",
    "            json.dump(behavior_report, f, indent=2)\n",
    "        \n",
    "        # Extract behavioral indicators from sandbox data\n",
    "        indicators = extract_behavioral_indicators(behavior_report)\n",
    "        \n",
    "        # Prepare result dictionary to store counts and info\n",
    "        result = {\n",
    "            'hash': hash_val,\n",
    "            'family': family,\n",
    "            'source': hash_info['source'],\n",
    "            'status': 'success',\n",
    "            'detection_ratio': None,\n",
    "            'first_seen': None,\n",
    "            'last_seen': None,\n",
    "            'processes_count': len(indicators['processes_created']),\n",
    "            'files_written_count': len(indicators['files_written']),\n",
    "            'files_deleted_count': len(indicators['files_deleted']),\n",
    "            'registry_keys_set_count': len(indicators['registry_keys_set']),\n",
    "            'dns_lookups_count': len(indicators['dns_lookups']),\n",
    "            'ip_connections_count': len(indicators['ip_traffic']),\n",
    "            'http_requests_count': len(indicators['http_conversations']),\n",
    "            'mutexes_count': len(indicators['mutexes_created']),\n",
    "            'mitre_techniques_count': len(indicators['mitre_techniques']),\n",
    "            'mitre_techniques': ', '.join([t.get('id', '') for t in indicators['mitre_techniques']]),\n",
    "            'collected_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        # Get detection stats and timestamps from file report, if available\n",
    "        if file_report['success']:\n",
    "            attrs = file_report['data'].get('data', {}).get('attributes', {})\n",
    "            stats = attrs.get('last_analysis_stats', {})\n",
    "            result['detection_ratio'] = f\"{stats.get('malicious', 0)}/{sum(stats.values())}\"\n",
    "            result['first_seen'] = attrs.get('first_submission_date', 'N/A')\n",
    "            result['last_seen'] = attrs.get('last_analysis_date', 'N/A')\n",
    "        \n",
    "        # Add current result to results list\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\"  âœ“ Success! Detections: {result['detection_ratio']}, \"\n",
    "              f\"MITRE Techniques: {result['mitre_techniques_count']}\")\n",
    "        \n",
    "        # Save progress every 5 samples\n",
    "        if idx % 5 == 0:\n",
    "            df_temp = pd.DataFrame(results)\n",
    "            df_temp.to_csv(f\"{output_dir}/analysis_results_partial.csv\", index=False)\n",
    "            print(f\"\\n  ðŸ’¾ Progress saved ({idx}/{total} completed)\\n\")\n",
    "        \n",
    "        # Wait before next request (except after last one)\n",
    "        if idx < total:\n",
    "            print(f\"  â³ Waiting {DELAY_BETWEEN_REQUESTS}s (rate limit)...\\n\")\n",
    "            time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "    \n",
    "    # Save final results as CSV and JSON\n",
    "    df_final = pd.DataFrame(results)\n",
    "    df_final.to_csv(f\"{output_dir}/analysis_results.csv\", index=False)\n",
    "    df_final.to_json(f\"{output_dir}/analysis_results.json\", orient=\"records\", indent=2)\n",
    "    \n",
    "    # Summary output to console\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"âœ“ Data collection complete!\")\n",
    "    print(f\"  Total samples: {total}\")\n",
    "    print(f\"  Successful: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "    print(f\"  Failed: {sum(1 for r in results if r['status'] == 'failed')}\")\n",
    "    print(f\"\\nResults saved to:\")\n",
    "    print(f\"  - {output_dir}/analysis_results.csv\")\n",
    "    print(f\"  - {output_dir}/analysis_results.json\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate a summary report based on collected results\n",
    "def generate_summary_report(results: List[Dict], output_dir: str = \"output\"):\n",
    "    # Convert results list to dataframe for analysis\n",
    "    df = pd.DataFrame(results)\n",
    "    # Filter only successful samples\n",
    "    successful = df[df['status'] == 'success']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COLLECTION SUMMARY REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Print basic summary counts\n",
    "    print(f\"\\nTotal samples processed: {len(results)}\")\n",
    "    print(f\"Successful collections: {len(successful)}\")\n",
    "    print(f\"Failed collections: {len(results) - len(successful)}\")\n",
    "    \n",
    "    if len(successful) > 0:\n",
    "        # Show count by malware family\n",
    "        print(f\"\\nSamples by Malware Family:\")\n",
    "        family_counts = successful['family'].value_counts()\n",
    "        for family, count in family_counts.items():\n",
    "            print(f\"  {family}: {count}\")\n",
    "        \n",
    "        # Show averages of behavioral indicators\n",
    "        print(f\"\\nBehavioral Indicators Summary:\")\n",
    "        print(f\"  Avg processes created: {successful['processes_count'].mean():.1f}\")\n",
    "        print(f\"  Avg files written: {successful['files_written_count'].mean():.1f}\")\n",
    "        print(f\"  Avg registry modifications: {successful['registry_keys_set_count'].mean():.1f}\")\n",
    "        print(f\"  Avg DNS lookups: {successful['dns_lookups_count'].mean():.1f}\")\n",
    "        print(f\"  Avg network connections: {successful['ip_connections_count'].mean():.1f}\")\n",
    "        \n",
    "        # MITRE ATT&CK technique coverage info\n",
    "        print(f\"\\nMITRE ATT&CK Coverage:\")\n",
    "        print(f\"  Samples with MITRE techniques: {(successful['mitre_techniques_count'] > 0).sum()}\")\n",
    "        print(f\"  Total unique techniques identified: {successful['mitre_techniques'].nunique()}\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23673a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MAIN EXECUTION START =====\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VirusTotal Malware Data Collection Script\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Define input and output paths\n",
    "    INPUT_FILE = \"./output/hash_signature_output.csv\"\n",
    "    OUTPUT_DIR = \"./output\"\n",
    "    \n",
    "    # Read hashes to process\n",
    "    hash_data = read_hash_file(INPUT_FILE)\n",
    "    \n",
    "    # Exit if no hashes found\n",
    "    if not hash_data:\n",
    "        print(\"No hashes found. Please check your input file.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Show number of hashes and preview first 3\n",
    "    print(f\"Found {len(hash_data)} hashes to process\")\n",
    "    print(\"\\nPreview of samples:\")\n",
    "    for i, h in enumerate(hash_data[:3], 1):\n",
    "        print(f\"  {i}. {h['hash'][:16]}... ({h['family']})\")\n",
    "    if len(hash_data) > 3:\n",
    "        print(f\"  ... and {len(hash_data) - 3} more\")\n",
    "    \n",
    "    # Ask user to confirm before starting data collection\n",
    "    response = input(\"\\nProceed with data collection? (yes/no): \").strip().lower()\n",
    "    \n",
    "    if response == 'yes':\n",
    "        # Collect data and save to files\n",
    "        results = collect_sample_data(hash_data, OUTPUT_DIR)\n",
    "        # Print summary report\n",
    "        generate_summary_report(results, OUTPUT_DIR)\n",
    "        print(\"\\nâœ“ All done! Check the output folder for results.\")\n",
    "    else:\n",
    "        print(\"\\nCollection cancelled.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
